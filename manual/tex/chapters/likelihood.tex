
\chapter{Likelihoods in optimization}
\label{ch:likelihoods-in-optimization}


\section{Definition of the system}


The discrete-time state-space formulation of a nonlinear dynamic system is\footnote{Refer to Appendix~\ref{ch:definition-of-terms} for the meaning of the symbols used in this Chapter.}:

\begin{equation}\label{eq:true-state}
x_{t+1}=f(x_t,u_t,\boldsymbol\theta)
\end{equation}
\begin{equation}\label{eq:true-output}
y_{t+1}=h(x_{t+1},\boldsymbol\phi)
\end{equation}
To keep notation as simple as possible, we consider a system in which the state, the forcing and the output at any given time can be represented as scalars. Further note that the `state' of the system at a given time can include history.
Since it is generally impossible to observe the true state, the true forcing, and the true output of a system, we have to make do with the observed state, observed forcing, and the observed output instead:

\begin{equation}\label{eq:observed-state}
\tilde{x}_{t+1}=x_{t+1} + \omega_{t+1}
\end{equation}
\begin{equation}\label{eq:observed-forcing}
\tilde{u}_{t+1}=u_{t+1} + \psi_{t+1}
\end{equation}
\begin{equation}\label{eq:observed-output}
\tilde{y}_{t+1}=y_{t+1} + \nu_{t+1}
\end{equation}
Note that Eqs.~\ref{eq:observed-state}--\ref{eq:observed-output} assume that the dimensionality of $x_{t+1}$, $u_{t+1}$ and $y_{t+1}$ is the same as their observed counterparts, and that they do indeed represent the same entities (in other words, there is no \textit{incommensurability}). Furthermore, we do not know the mechanism by which $x_t$ leads to $x_{t+1}$ in Eq.~\ref{eq:true-state}, so instead we propose a mechanism $\hat{f}(\cdot{})$; similarly we do not know how $x_{t+1}$ leads to $y_{t+1}$ in Eq.~\ref{eq:true-output}, so we propose $\hat{h}(\cdot{})$. Typically, $\hat{f}(\cdot{})$ and $\hat{h}(\cdot{})$ are part of the same computer model structure. Because of philosophical reasons \citep[e.g.][]{popp-2009}, it is impossible to prove that $\hat{f}(\cdot{})$ and $\hat{h}(\cdot{})$ are in fact the correct functions $f(\cdot{})$ and $h(\cdot{})$---instead, we can only subject $\hat{f}(\cdot{})$ and $\hat{h}(\cdot{})$ to increasingly difficult tests, and if $\hat{f}(\cdot{})$ and $\hat{h}(\cdot{})$ are not falsified by these tests, then the confidence in the correctness of $\hat{f}(\cdot{})$ and $\hat{h}(\cdot{})$ increases.



\section{Constructing a likelihood for a simple error model}
The probability of sampling a value $x$ from a normal distribution  is calculated with:
\begin{equation}\label{eq:normal-distribution}
p\,(\,x\,|\,\mu,\sigma\,) = \frac{1}{\sqrt{2\pi\sigma^2}}\:e^\mathlarger{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
\end{equation}
Within the context of calibration, this is equivalent to:
\begin{equation}\label{eq:normal-distribution-calibration}
p\,(\,\hat{x}\,|\,\tilde{x},\sigma\,) = \frac{1}{\sqrt{2\pi\sigma^2}}\:e^\mathlarger{-\frac{1}{2}\left(\frac{\hat{x}-\tilde{x}}{\sigma}\right)^2}
\end{equation}
Note that this assumes that the true mean of the distribution can be observed, i.e.\,$\tilde{x}=\mu$.

For the case where we have not just 1 observation, but instead have a time series of $n_o$ observations, the probability $p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\boldsymbol\sigma\,)$ is calculated as the product of all individual probabilities\footnote{Note that this can be extended to deal with non-constant variance (\textit{heteroscedasticity}) by making $\sigma$ into a vector $\boldsymbol\sigma$:
\begin{equation}\label{eq:heteroscedastic-normal-distribution-calibration}
p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\boldsymbol\sigma\,) = \prod_{t=1}^{n_o} \frac{1}{\sqrt{2\pi\sigma_t^2}}\:e^\mathlarger{-\frac{1}{2}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma_t}\right)^2}\nonumber
\end{equation}}:
\begin{equation}\label{eq:normal-distribution-calibration-prod}
p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = \prod_{t=1}^{n_o} \frac{1}{\sqrt{2\pi\sigma^2}}\:e^\mathlarger{-\frac{1}{2}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2}
\end{equation}
Note that the multiplication of individual probabilities in Eq.~\ref{eq:normal-distribution-calibration} reflects the implicit assumption that the errors are independent---an assumption that is often violated.

\vspace{1em}
Since $\frac{1}{\sqrt{2\pi\sigma^2}}$ is constant for homoscedastic problems, Eq.~\ref{eq:normal-distribution-calibration} can be rearranged as follows:
\begin{equation}\label{eq:normal-distribution-calibration2}
p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = \left[\frac{1}{\sqrt{2\pi\sigma^2}}\right]^{n_o}\:\cdot{}\:\prod_{t=1}^{n_o}\:e^\mathlarger{-\frac{1}{2}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2}
\end{equation}
and since:
\begin{equation}
\left[\frac{1}{\sqrt{2\pi\sigma^2}}\right]^{n_o} = \left[\sqrt{2\pi\sigma^2}\right]^{-n_o} \nonumber
\end{equation}
Eq.~\ref{eq:normal-distribution-calibration2} can be rewritten as:
\begin{equation}\label{eq:normal-distribution-calibration3}
p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = \left[\sqrt{2\pi\sigma^2}\right]^{-n_o}\:\cdot{}\:\prod_{t=1}^{n_o}\:e^\mathlarger{-\frac{1}{2}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2}
\end{equation}
Furthermore,
\begin{equation}
e^a\cdot{}e^b=e^{a+b}
\end{equation}
so Eq.~\ref{eq:normal-distribution-calibration3} may be written as:
\begin{equation}\label{eq:normal-distribution-calibration4}
p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = \left[\sqrt{2\pi\sigma^2}\right]^{-n_o}\:\cdot{}\:e^\mathlarger{-\frac{1}{2}\sum_{t=1}^{n_o}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2}
\end{equation}
The probability density in Eq.~\ref{eq:normal-distribution-calibration4} is related to the \textit{log-likelihood} according to\footnote{Note that $\hat{\mathbf{x}}$ in Eq.~\ref{eq:log-likelihood1} is only dependent on the parameter vector  $\boldsymbol\theta$, while the observations $\tilde{\mathbf{x}}$ and $\sigma$ are given. When a probability is a function of the parameter value, `likelihood' is preferred over `probability'.}:
\begin{align}\label{eq:log-likelihood1}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) &= \mathrm{ln}\left(\,p\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,)\,\right)\\
&=\mathrm{ln}\left(\left[\sqrt{2\pi\sigma^2}\right]^{-n_o}\cdot{}e^\mathlarger{-\frac{1}{2}\sum_{t=1}^{n_o}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2}
\right)
\end{align}
and since:
\begin{equation}\label{eq:log-multiplication}
\mathrm{ln}\left(a\cdot{}b\right) = \mathrm{ln}\left(a\right) + \mathrm{ln}\left(b\right),
\end{equation}
\begin{equation}\label{eq:log-power}
\mathrm{ln}\left(a^b\right) = b \cdot \mathrm{ln}\left(a\right),
\end{equation}
\begin{equation}
\mathrm{ln}\left(e^a\right) = a,
\end{equation}
Eq.~\ref{eq:log-likelihood1} can be rewritten as:
\begin{equation}\label{eq:log-likelihood2}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = -n_o \cdot{} \mathrm{ln}\left[\sqrt{2\pi\sigma^2}\right]\:+\:\left[-\frac{1}{2}\sum_{t=1}^{n_o}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2\right]
\end{equation}
Subsequently applying Eqs.~\ref{eq:log-power} and \ref{eq:log-multiplication}, Eq.~\ref{eq:log-likelihood2} can be rewritten as:
\begin{equation}\label{eq:log-likelihood3}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sigma^2\right)\:-\:\frac{1}{2}\sum_{t=1}^{n_o}\left(\frac{\hat{x}_t-\tilde{x}_t}{\sigma}\right)^2
\end{equation}
to yield the Gaussian log-likelihood function with unknown standard deviation $\sigma$ of the residuals $\hat{x}_t-\tilde{x}_y$. It is convenient to rewrite Eq.~\ref{eq:log-likelihood3} as follows:
\begin{equation}\label{eq:log-likelihood4}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}},\sigma\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sigma^2\right)\:-\:\frac{1}{2}\sum_{t=1}^{n_o}\frac{\left(\hat{x}_t-\tilde{x}_t\right)^2}{\sigma^2}
\end{equation}

For many measuring devices, $\sigma^2$ is either known or can be determined by simple experiments. If necessary, $\sigma^2$ can also be estimated from the observations according to\footnote{This implicitly assumes that parameter uncertainty is the only source of uncertainty.}:
\begin{equation}\label{eq:variance-estimator}
s^2 = \frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2
\end{equation}

Replacing $\sigma^2$ with $s^2$ in Eq.~\ref{eq:log-likelihood4} yields:
\begin{equation}\label{eq:log-likelihood4}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}}\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(s^2\right)\:-\:\frac{1}{2}\sum_{t=1}^{n_o}\frac{\left(\hat{x}_t-\tilde{x}_t\right)^2}{s^2}
\end{equation}
which is equal to:
\begin{equation}\label{eq:log-likelihood6}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}}\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)\:-\:\frac{1}{2}\frac{\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2}{\frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2}
\end{equation}
Simplification of the last term in Eq.~\ref{eq:log-likelihood6} yields:
\begin{equation}\label{eq:log-likelihood7}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}}\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)\:-\:\frac{1}{2}\left(n_o-1\right)
\end{equation}

Application of Eq.~\ref{eq:log-multiplication} to the second term in Eq.~\ref{eq:log-likelihood7} yields:
\begin{equation}\label{eq:log-likelihood8}
-\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\frac{1}{n_o-1}\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)
\end{equation}
and since
\begin{equation}\label{eq:log-division}
\mathrm{ln}\left(\frac{a}{b}\right) = \mathrm{ln}\left(a\right)\:-\:\mathrm{ln}\left(b\right)
\end{equation}
and
\begin{equation}\label{eq:log1}
\mathrm{ln}(1) = 0,
\end{equation}
Eq.~\ref{eq:log-likelihood8} thus becomes:
\begin{equation}\label{eq:log-likelihood9}
-\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\frac{1}{n_o-1}\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right) = +\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(n_o-1\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)
\end{equation}

Filling Eq.~\ref{eq:log-likelihood9} back into Eq.~\ref{eq:log-likelihood7} yields:
\begin{equation}\label{eq:log-likelihood10}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}}\,) = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:+\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(n_o-1\right)\:-\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)\:-\:\frac{1}{2}\left(n_o-1\right)
\end{equation}

For a given number of observations $n_o$, terms 1, 2, and 4 from Eq.~\ref{eq:log-likelihood10} may be collected into a constant $C$ as follows:

\begin{equation}\label{eq:log-likelihood11}
\ell\,(\,\hat{\mathbf{x}}\,|\,\tilde{\mathbf{x}}\,) = -\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(\sum_{t=1}^{n_o}\left(\hat{x}_t-\tilde{x}_t\right)^2\right)\:+\:C
\end{equation}
with
\begin{equation}\label{eq:constant-c}
C = -\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(2\pi\right)\:+\:\frac{1}{2}n_o\cdot{}\mathrm{ln}\left(n_o-1\right)\:-\:\frac{1}{2}\left(n_o-1\right)
\end{equation}


When constructing log likelihood functions for MMSODA, we may safely leave out the $C$ term. This is because MMSODA uses the Metropolis algorithm to determine whether a new sample of the parameter space should be accepted or rejected. Whether a new sample is accepted depends on how its likelihood $\ell_{new}$ compares to the likelihood associated with a previous sample $\ell_{prev}$. A sample is accepted if
\begin{equation}\label{eq:log-metropolis}
\ell_{new}-\ell_{prev}\:>\:\mathrm{ln}(z)}
\end{equation}
with $z$ a draw from a uniform distribution between 0 and 1:
\begin{equation}\label{eq:draw-from-uniform}
z\:\sim\:U(0,1)
\end{equation}
In other words, if $\ell_{new}$ is an improvement relative to $\ell_{prev}$, the new point is always accepted; if $\ell_{new}$ is slightly worse than $\ell_{prev}$, it is still quite likely that the new point will be accepted; if $\ell_{new}$ is much worse than $\ell_{prev}$ it is unlikely, but not impossible, that the new point will be accepted.

Since raising both $\ell_{new}$ and $\ell_{prev}$ by the constant $C$ has no effect on the distance $\ell_{new}\:-\:\ell_{prev}$, $C$ may be left out of the objective function entirely.






%\section{Bayes' law in parameter optimization}


%Eq.~\ref{eq:bayes-law-general} shows Bayes' Law:
%\begin{equation}\label{eq:bayes-law-general}
%p(A|B) = \frac{p(B|A)\:p(A)}{p(B)}
%\end{equation}
%It describes how a prior belief in something can be modified or strengthened as a result of observations. For example, within the context of parameter estimation, it describes how a \textit{prior} belief in the value of a parameter vector, or $p(\boldsymbol\theta)$, can be modified by something called the \textit{likelihood}, or $p(\tilde{\mathbf{x}}|\boldsymbol\theta)$, to yield a \textit{posterior} belief in the value of the parameter vector, or $p(\boldsymbol\theta|\tilde{\mathbf{x}})$,  according to Eq.~\ref{eq:bayes-law} ($p(\tilde{\mathbf{x}})$ is just a normalization constant):
%\begin{equation}\label{eq:bayes-law}
%p(\boldsymbol\theta|\tilde{\mathbf{x}}) = \frac{p(\tilde{\mathbf{x}}|\boldsymbol\theta)\:p(\boldsymbol\theta)}{p(\tilde{\mathbf{x}})}
%\end{equation}

%In Bayesian parameter estimation, we want to quantify the uncertainty of the parameter vector $\boldsymbol\theta$ given some observed data $\tilde{\mathbf{x}}$, or:
%\begin{equation}
%p(\boldsymbol\theta|\mathbf{\tilde{x}})
%\end{equation}
%
%
%For example, if the real system behavior is characterized by a vector of state values $\mathbf{x} = x_1,x_2,\ldots,x_{n_o-1},x_{n_o}$, then we may have observations $\mathbf{\tilde{x}} = \tilde{x}_1,\tilde{x}_2,\ldots,\tilde{x}_{n_o-1},\tilde{x}_{n_o}$ of it.
%
%
%In order to calculate this probability we can split it into:
%
%In Eq.~\ref{eq:bayes-law}, $p(\mathbf{\tilde{x}}|\boldsymbol\theta)$ is referred to as the \textit{conditional probability} or \textit{likelihood}, $p(\boldsymbol\theta)$ is referred to as the \textit{prior}, $p(\mathbf{\tilde{x}})$ is called the \textit{evidence}, and finally, $p(\boldsymbol\theta|\mathbf{\tilde{x}})$ is known as the \textit{posterior}. Eq.~\ref{eq:bayes-law} is known as Bayes' Law.
%




